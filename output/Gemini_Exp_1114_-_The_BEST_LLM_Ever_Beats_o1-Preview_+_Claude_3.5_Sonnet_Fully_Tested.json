{"speakers": [], "chunks": [{"timestamp": [0.0, 7.52], "text": " Looks like we have a new king! Google's new Gemini experimental model 1114 has taken the AI community"}, {"timestamp": [7.52, 13.68], "text": " by storm as it currently ranks number one on the chatbot arena benchmark and it is outperforming"}, {"timestamp": [13.68, 20.08], "text": " heavyweights like the 01 preview as well as cloud 3.5 sonnet. Now this milestone is even more"}, {"timestamp": [20.08, 25.28], "text": " remarkable as the model also ranks first on the vision leaderboard which is showcasing its"}, {"timestamp": [25.28, 31.52], "text": " dominance in both natural language and visual ai tasks now this new experimental model seems to be"}, {"timestamp": [31.52, 37.28], "text": " prioritizing precision and reasoning it is slightly slower in terms of its response times"}, {"timestamp": [37.28, 43.84], "text": " and it features a 32k context length which is kind of restrictive but it is currently an experimental"}, {"timestamp": [43.84, 45.38], "text": " and they're obviously using it to"}, {"timestamp": [45.38, 50.56], "text": " test out its specialized capabilities. And something to also note is that there's a lack"}, {"timestamp": [50.56, 56.28], "text": " of tags that you would see with any Gemini experimental model where there is no pro or"}, {"timestamp": [56.28, 63.0], "text": " flash tag in the name, which definitely hints something new, maybe an ultra model or a new pro"}, {"timestamp": [63.0, 65.24], "text": " model or even a new Flash model."}, {"timestamp": [71.22, 71.76], "text": " Now, like I mentioned, the chatbot arena showcases this experimental model as ranked number one."}, {"timestamp": [76.62, 81.62], "text": " And basically, for the people who do not know, this arena benchmark is a community-driven platform for live evaluations and pairwise comparisons of different LMs."}, {"timestamp": [81.72, 85.26], "text": " It's regarded as one of the most unbiased standards in the space,"}, {"timestamp": [85.64, 91.56], "text": " which is securing the top most solidified rankings of different LMs. And we can see that this model"}, {"timestamp": [91.56, 95.9], "text": " is currently ranked number one versus many of these other models that are out there."}, {"timestamp": [96.16, 100.6], "text": " On Google AI Studio, you can actually access this model right now. So if you're interested,"}, {"timestamp": [100.82, 107.72], "text": " you can get started with it right away. If you go over to the preview tab, you can select the new 1114 model and you can start"}, {"timestamp": [107.72, 108.52], "text": " chatting with it."}, {"timestamp": [109.06, 113.3], "text": " Now, before we even get to the test, I want you to take a look at this table, which is"}, {"timestamp": [113.3, 115.26], "text": " showcasing the chatbot arena leaderboard."}, {"timestamp": [115.26, 121.68], "text": " But now we're taking a look a bit further in the performance of LMs across various tasks."}, {"timestamp": [122.14, 128.84], "text": " Now, this experimental model ranks obviously number 1 overall, which is excelling in categories like mathematics,"}, {"timestamp": [128.84, 133.2], "text": " creative writing, instruction following, and multi-turn conversations."}, {"timestamp": [133.2, 139.06], "text": " It's slightly behind in coding and hard prompts with style control, and it's ranked number"}, {"timestamp": [139.06, 145.36], "text": " 3 in both, and it outperforms strong competitors with with ChatGBT as well as OWN Preview."}, {"timestamp": [145.92, 151.46], "text": " Now, its dominance across key areas like math as well as instruction following"}, {"timestamp": [151.46, 156.62], "text": " tends to round up its top tier capabilities, which is why it is ranked number one."}, {"timestamp": [156.62, 160.92], "text": " So now what we're going to be doing is testing out the new Gemini experimental model."}, {"timestamp": [161.2, 165.36], "text": " We're going to be assessing it in various categories from mathematics to logical"}, {"timestamp": [165.36, 172.0], "text": " reasoning to coding and so much more we're going to first start off by replicating this patreon ui"}, {"timestamp": [172.0, 177.92], "text": " to test out its visual capabilities as well as its coding capabilities so let's head over to the"}, {"timestamp": [177.92, 185.52], "text": " gemini ai studio and let's paste in the image that we want to replicate. So I'm going to go ahead and feed it the context."}, {"timestamp": [185.86, 187.82], "text": " So let's go over to our desktop."}, {"timestamp": [188.3, 191.06], "text": " I think I did copy this image."}, {"timestamp": [191.36, 193.66], "text": " And now I'm going to request it to replicate this UI."}, {"timestamp": [194.32, 197.3], "text": " Please replicate this UI for me."}, {"timestamp": [198.3, 200.88], "text": " Let's send it in by clicking run."}, {"timestamp": [200.88, 206.14], "text": " And within a couple of seconds, we should have the model process this image with"}, {"timestamp": [206.14, 219.16], "text": " html and css code and it looks like it has finished generating the content so i'm gonna go"}, {"timestamp": [219.16, 226.42], "text": " ahead and paste in the html as well as css code into a file to see how it basically looks. So I went along and"}, {"timestamp": [226.42, 232.7], "text": " I copied the HTML code and the CSS code and I was able to get this output. Isn't that amazing?"}, {"timestamp": [233.06, 237.66], "text": " This is the capability of this new Gemini experimental model in terms of its visual"}, {"timestamp": [237.66, 243.32], "text": " capabilities where it can replicate and it's capable of doing quite well in terms of coding"}, {"timestamp": [243.32, 246.08], "text": " tasks. So this is definitely a pass."}, {"timestamp": [246.3, 250.32], "text": " So let's give this a pass and let's now move on to the next benchmark test."}, {"timestamp": [250.9, 256.38], "text": " Next up, we're going to be asking it to solve a mathematical problem. We're going to ask it if a"}, {"timestamp": [256.38, 262.24], "text": " train travels at 60 miles per hour for 2.5 hours, then increases its speed for 75 miles an hour"}, {"timestamp": [262.24, 266.64], "text": " for the next 1.5 hours. What is the total distance that has been"}, {"timestamp": [266.64, 271.74], "text": " traveled? So let's go ahead and send this in and let's see if it's accurately able to provide the"}, {"timestamp": [271.74, 277.86], "text": " right answer with the right steps. Now, the reason why we're asking this is because it evaluates"}, {"timestamp": [277.86, 283.64], "text": " arithmetic calculations, unit consistency, as well as logical reasoning in multi-step problems."}, {"timestamp": [284.02, 285.2], "text": " And right away from what i"}, {"timestamp": [285.2, 291.52], "text": " can see is that this model does a great job in logically providing multiple steps and we can see"}, {"timestamp": [291.52, 298.26], "text": " that it utilizes the correct formula which is speed times time and then we can see that it is"}, {"timestamp": [298.26, 308.32], "text": " able to provide the correct answer which is 262.5 miles so therefore this is definitely deemed a pass now next we're gonna have it generate an"}, {"timestamp": [308.32, 314.8], "text": " svg code for a butterfly shape now this is under the category of coding and this is something that"}, {"timestamp": [314.8, 320.32], "text": " many models tend to fail every model that i've tested have has failed this other than the cloud"}, {"timestamp": [320.32, 326.2], "text": " 3.5 sonnet as well as the o1 preview. But let's see if this model is capable of doing"}, {"timestamp": [326.2, 332.36], "text": " this. It's basically testing the understanding of SVG syntax as well as geometric concepts such as"}, {"timestamp": [332.36, 338.12], "text": " symmetry and the ability to generate structured accurate code. So I'm gonna go ahead and copy this"}, {"timestamp": [338.12, 346.32], "text": " and I'm gonna go over to an SVG code simulator to see if this is real. So let's go ahead and copy this and let's go over to an SVG"}, {"timestamp": [346.32, 351.96], "text": " viewer and paste this in. And look at that. Surprisingly, it is accurate. And this does"}, {"timestamp": [351.96, 357.08], "text": " look like a butterfly in my opinion. And this is quite surprising because many models tend to fail"}, {"timestamp": [357.08, 363.74], "text": " at doing this task. So this is a really good sign to see that it is passing at generating SVG code."}, {"timestamp": [364.04, 366.4], "text": " Now, next up, we're going to have it design"}, {"timestamp": [366.4, 372.84], "text": " an algorithm to optimize a layout for a warehouse. So we can go back into Gemini Studio and then"}, {"timestamp": [372.84, 379.04], "text": " paste in this prompt. Now, essentially, this is a prompt that is under the problem solving and"}, {"timestamp": [379.04, 385.12], "text": " algorithm design category, where we're trying to measure abstract problem-solving as well as"}, {"timestamp": [385.12, 390.38], "text": " algorithmic thinking as well as the ability to balance competing priorities"}, {"timestamp": [390.38, 395.24], "text": " now what we're trying to look for in this prompt is where it's capable of"}, {"timestamp": [395.24, 399.98], "text": " using graph data structures as well as implementing algorithms or dynamic"}, {"timestamp": [399.98, 405.42], "text": " programming right off the bat I can see that it is focusing on applying different algorithms"}, {"timestamp": [405.42, 412.6], "text": " such as ABC analysis. You have cube per order index as well as clustering algorithms like K-means"}, {"timestamp": [412.6, 418.4], "text": " where it is grouping frequently ordered items together. So we can see that it does a great job"}, {"timestamp": [418.4, 424.44], "text": " in listing out the algorithms as well as handling the trade-offs and implementation steps. So this"}, {"timestamp": [424.44, 426.02], "text": " is definitely deemed a pass."}, {"timestamp": [426.22, 428.34], "text": " So I'm going to go ahead and give this a pass."}, {"timestamp": [428.46, 433.74], "text": " Next up, we're going to have it create the Python implementation of Conway's Game of Life."}, {"timestamp": [434.22, 439.86], "text": " Now, every model tends to do a good job in terms of generating the code for this,"}, {"timestamp": [439.86, 444.3], "text": " but it is kind of wonky at certain times with many open source models."}, {"timestamp": [444.76, 448.26], "text": " The only model that I saw it was capable of generating a full game of this"}, {"timestamp": [448.26, 452.44], "text": " was the Cloud 3.5 Sonnet as well as the O1 Preview."}, {"timestamp": [452.44, 456.42], "text": " So let's go ahead and see if it's able to create the basic Python script for it."}, {"timestamp": [456.8, 461.56], "text": " And essentially, this is where we're testing algorithmic implementation,"}, {"timestamp": [461.96, 465.82], "text": " knowledge of cellular autonomy, as well as the ability to structure"}, {"timestamp": [465.82, 470.38], "text": " terminal output. So once I've finished generating this, I'm going to go ahead and paste this into"}, {"timestamp": [470.38, 476.66], "text": " a Python file to see if this is accurate. So I've copied the code and I've pasted it into"}, {"timestamp": [476.66, 482.42], "text": " a VS Code Python file. So let's go ahead and see if it's functional. And there we go. It is"}, {"timestamp": [482.42, 487.26], "text": " definitely functional. It is autonomously generating the game of life so let's go"}, {"timestamp": [487.26, 489.9], "text": " ahead into our benchmark test and give this a pass"}, {"timestamp": [489.9, 494.28], "text": " moving forward we have another prompt which is going to assess"}, {"timestamp": [494.28, 498.22], "text": " logic as well as puzzle so let's go back into"}, {"timestamp": [498.22, 501.56], "text": " the ai studio and paste in this prompt essentially"}, {"timestamp": [501.56, 505.32], "text": " this is where we're assessing how well the model is in"}, {"timestamp": [505.32, 508.94], "text": " terms of evaluating logical reasoning and problem-solving capabilities with"}, {"timestamp": [508.94, 513.28], "text": " constraints because this is where we're asking you have a three gallon jug and a"}, {"timestamp": [513.28, 517.28], "text": " five gallon jug how can you measure four gallons of water efficiently now"}, {"timestamp": [517.28, 522.86], "text": " essentially you have to use a six step process in this case we have that six"}, {"timestamp": [522.86, 526.0], "text": " step process being recognized over here where you"}, {"timestamp": [526.0, 531.92], "text": " fill up the five gallon jug completely you then pour the water from the five gallon into the three"}, {"timestamp": [531.92, 538.4], "text": " gallon until the ladder is full leaving two gallons in the five gallon jug and essentially"}, {"timestamp": [538.4, 546.36], "text": " you'll you're going to be left off with four gallons remaining in the five gallon jug which is definitely correct so this is something"}, {"timestamp": [546.36, 552.46], "text": " that is definitely a pass on the benchmark sheet and that is really really good to see"}, {"timestamp": [552.46, 560.72], "text": " now next up we have this question that is focusing on writing and empathy so let's go ahead into the"}, {"timestamp": [560.72, 566.12], "text": " studio and send in this prompt this is where we're focusing on how well the model is"}, {"timestamp": [566.12, 569.44], "text": " in terms of emotional intelligence, as well as empathy,"}, {"timestamp": [569.44, 572.48], "text": " as well as its written communication skills."}, {"timestamp": [572.48, 574.0], "text": " So right off the bat,"}, {"timestamp": [574.0, 577.04], "text": " you can see that it's asking a question back to us"}, {"timestamp": [577.04, 579.88], "text": " where it's asking in a human-like manner."}, {"timestamp": [579.88, 583.16], "text": " Now I'm gonna go ahead and I'm gonna keep on writing"}, {"timestamp": [583.16, 585.4], "text": " to see what it's able to generate and how"}, {"timestamp": [585.4, 590.52], "text": " it's able to communicate with me. So essentially what the prompt is saying is that a friend tells"}, {"timestamp": [590.52, 595.26], "text": " you that he didn't get a job that he really wanted. So I'm requesting it to craft an empathetic"}, {"timestamp": [595.26, 599.76], "text": " response and acknowledge their feelings. So we can see right off the bat, the model responds,"}, {"timestamp": [599.96, 603.42], "text": " oh, I'm so sorry to hear that. And it's totally understandable that you're disappointed,"}, {"timestamp": [603.76, 605.6], "text": " especially since you really wanted that job."}, {"timestamp": [605.68, 606.72], "text": " That must be rough."}, {"timestamp": [607.0, 609.6], "text": " And you can see that this is showcasing"}, {"timestamp": [609.6, 612.84], "text": " an empathetic response back to the person."}, {"timestamp": [612.84, 615.1], "text": " And we can see that it is asking questions"}, {"timestamp": [615.1, 616.28], "text": " on what you're thinking."}, {"timestamp": [616.64, 618.58], "text": " So I stated that the friend was thinking"}, {"timestamp": [618.58, 620.96], "text": " about feeling hopeless and nothing going his way."}, {"timestamp": [621.36, 623.22], "text": " And then you can see that it is showing"}, {"timestamp": [623.22, 626.12], "text": " lots of levels of empathy in this"}, {"timestamp": [626.12, 632.06], "text": " response over here and this is definitely something that is showcasing strong emotional intelligence"}, {"timestamp": [632.06, 637.68], "text": " so i'm going to go ahead to the benchmark test and give this a pass so far it has been succeeding"}, {"timestamp": [637.68, 646.84], "text": " really really well now next up we're going to be testing the ethical category of how well this model is in terms of providing"}, {"timestamp": [646.84, 653.3], "text": " a good ethical response. So let's go back into the studio and let's have it generate a response."}, {"timestamp": [653.72, 658.6], "text": " The prompt is asking, a self-driven car must choose between hitting a group of pedestrians"}, {"timestamp": [658.6, 663.7], "text": " or swerving and likely killing its single passenger. What ethical considerations are"}, {"timestamp": [663.7, 671.08], "text": " involved in programming such decisions? Now, what we're trying to see is if it's able to consider utilitarianism,"}, {"timestamp": [671.08, 676.88], "text": " where there's minimizing overall harm. You also have transparency, legal implications,"}, {"timestamp": [677.34, 682.3], "text": " and public trust. And right off the bat, we can see that it is focusing on a lot of these"}, {"timestamp": [682.3, 687.04], "text": " different things. And it's also emphasizing on a lot of other considerations."}, {"timestamp": [687.6, 691.54], "text": " So this is something where it's focusing on deontology and rights,"}, {"timestamp": [691.6, 695.2], "text": " where it's focusing on the perspective of emphasizing moral duties,"}, {"timestamp": [695.2, 699.92], "text": " as well as preserving the passenger's right of safety, justice and fairness,"}, {"timestamp": [700.44, 703.26], "text": " public acceptance and trust, and so much more."}, {"timestamp": [703.64, 706.3], "text": " So there's no single right answer to these ethical"}, {"timestamp": [706.3, 711.74], "text": " questions and that is definitely correct because it is something where you're considering various"}, {"timestamp": [711.74, 717.94], "text": " sorts of views and perspectives to give a basis of this answer so this is definitely deemed a pass"}, {"timestamp": [717.94, 723.82], "text": " on this benchmark test now next up we're going to have it write a short story in approximately 150"}, {"timestamp": [723.82, 727.12], "text": " words so let's go back into this video and send this in now what we're going to have it write a short story in approximately 150 words. So let's go back into the studio and send this in."}, {"timestamp": [727.58, 745.42], "text": " Now, what we're trying to see with this is if it's focusing on a good creative theme where it effectively"}, {"timestamp": [745.42, 751.3], "text": " explores a butterfly effect scenario with a significant historical consequence it focuses"}, {"timestamp": [751.3, 756.74], "text": " on a narrative structure where it's clear where there's two different paragraphs focuses on a"}, {"timestamp": [756.74, 761.7], "text": " conflict as well as a resolution within this last paragraph and there's adherence to the prompt"}, {"timestamp": [761.7, 765.44], "text": " where it focuses on closely focusing on time travel"}, {"timestamp": [765.44, 767.5], "text": " and historical change as a theme."}, {"timestamp": [767.94, 770.12], "text": " Now, this is definitely deemed a pass."}, {"timestamp": [770.46, 773.42], "text": " So let's go ahead into our benchmark test and give this a pass."}, {"timestamp": [773.94, 778.7], "text": " Lastly, we're going to have it explain the difference between irony and sarcasm and provide"}, {"timestamp": [778.7, 779.74], "text": " an example for each."}, {"timestamp": [779.74, 787.26], "text": " Now, this is obviously a really basic prompt, but essentially it tests the model in terms of its language and knowledge."}, {"timestamp": [787.42, 795.54], "text": " And it focuses on evaluating the understanding of nouns, languages, as well as its concepts and the ability to provide clear examples for each."}, {"timestamp": [795.54, 806.72], "text": " And right off the bat, we can see for sarcasm, it defines it and it provides a breakdown with each example, focusing on irony irony whether that's situational and where it focuses"}, {"timestamp": [806.72, 812.76], "text": " on a lot of different types of irony from verbal situational and dramatic so this is definitely"}, {"timestamp": [812.76, 818.42], "text": " deemed a pass and this is the first time where i've seen on this channel where a model is able to"}, {"timestamp": [818.42, 825.16], "text": " pass all of these different prompts so huge props to the google Gemini team obviously these are just"}, {"timestamp": [825.16, 829.6], "text": " simple benchmark tests from testing a model in terms of how well it's able to"}, {"timestamp": [829.6, 834.68], "text": " provide generations for various categories but you can see that even"}, {"timestamp": [834.68, 839.72], "text": " with the chatbot arena where it's able to provide great scores on arena vision"}, {"timestamp": [839.72, 844.0], "text": " as well as on the main arena benchmark test we can see that this model even"}, {"timestamp": [844.0, 847.72], "text": " outpaces many of these other models that's out there on"}, {"timestamp": [847.72, 849.98], "text": " a community driven evaluation."}, {"timestamp": [849.98, 852.86], "text": " Now this is a model that I definitely recommend that you try out."}, {"timestamp": [852.86, 857.54], "text": " You can access it currently for free off of Google's AI Studio, which I'll leave a link"}, {"timestamp": [857.54, 859.08], "text": " to in the description below."}, {"timestamp": [859.08, 861.16], "text": " But that's essentially it for this model guys."}, {"timestamp": [861.16, 863.0], "text": " I definitely love what Google is doing."}, {"timestamp": [863.0, 872.16], "text": " This is the first time ever where they have outpaced opening as flagship models as well as anthropics flagship models i'll leave all the"}, {"timestamp": [872.16, 876.28], "text": " links that i use in today's video in the description below make sure you follow me on the patreon so"}, {"timestamp": [876.28, 881.82], "text": " that you can access our patreon subscriptions that we give out on a monthly basis for free"}, {"timestamp": [881.82, 890.18], "text": " make sure you follow me on twitter a great way for you to stay up to date with whatever is happening in the world of ai lastly subscribe turn on notification bell like"}, {"timestamp": [890.18, 894.26], "text": " this video and check out our previous videos so that you can stay up to date with whatever is"}, {"timestamp": [894.26, 899.24], "text": " happening in the world of ai but with that thought guys have an amazing day spread positivity and"}, {"timestamp": [899.24, 901.4], "text": " i'll see you guys fairly shortly peace out fellas"}], "text": " Looks like we have a new king! Google's new Gemini experimental model 1114 has taken the AI community by storm as it currently ranks number one on the chatbot arena benchmark and it is outperforming heavyweights like the 01 preview as well as cloud 3.5 sonnet. Now this milestone is even more remarkable as the model also ranks first on the vision leaderboard which is showcasing its dominance in both natural language and visual ai tasks now this new experimental model seems to be prioritizing precision and reasoning it is slightly slower in terms of its response times and it features a 32k context length which is kind of restrictive but it is currently an experimental and they're obviously using it to test out its specialized capabilities. And something to also note is that there's a lack of tags that you would see with any Gemini experimental model where there is no pro or flash tag in the name, which definitely hints something new, maybe an ultra model or a new pro model or even a new Flash model. Now, like I mentioned, the chatbot arena showcases this experimental model as ranked number one. And basically, for the people who do not know, this arena benchmark is a community-driven platform for live evaluations and pairwise comparisons of different LMs. It's regarded as one of the most unbiased standards in the space, which is securing the top most solidified rankings of different LMs. And we can see that this model is currently ranked number one versus many of these other models that are out there. On Google AI Studio, you can actually access this model right now. So if you're interested, you can get started with it right away. If you go over to the preview tab, you can select the new 1114 model and you can start chatting with it. Now, before we even get to the test, I want you to take a look at this table, which is showcasing the chatbot arena leaderboard. But now we're taking a look a bit further in the performance of LMs across various tasks. Now, this experimental model ranks obviously number 1 overall, which is excelling in categories like mathematics, creative writing, instruction following, and multi-turn conversations. It's slightly behind in coding and hard prompts with style control, and it's ranked number 3 in both, and it outperforms strong competitors with with ChatGBT as well as OWN Preview. Now, its dominance across key areas like math as well as instruction following tends to round up its top tier capabilities, which is why it is ranked number one. So now what we're going to be doing is testing out the new Gemini experimental model. We're going to be assessing it in various categories from mathematics to logical reasoning to coding and so much more we're going to first start off by replicating this patreon ui to test out its visual capabilities as well as its coding capabilities so let's head over to the gemini ai studio and let's paste in the image that we want to replicate. So I'm going to go ahead and feed it the context. So let's go over to our desktop. I think I did copy this image. And now I'm going to request it to replicate this UI. Please replicate this UI for me. Let's send it in by clicking run. And within a couple of seconds, we should have the model process this image with html and css code and it looks like it has finished generating the content so i'm gonna go ahead and paste in the html as well as css code into a file to see how it basically looks. So I went along and I copied the HTML code and the CSS code and I was able to get this output. Isn't that amazing? This is the capability of this new Gemini experimental model in terms of its visual capabilities where it can replicate and it's capable of doing quite well in terms of coding tasks. So this is definitely a pass. So let's give this a pass and let's now move on to the next benchmark test. Next up, we're going to be asking it to solve a mathematical problem. We're going to ask it if a train travels at 60 miles per hour for 2.5 hours, then increases its speed for 75 miles an hour for the next 1.5 hours. What is the total distance that has been traveled? So let's go ahead and send this in and let's see if it's accurately able to provide the right answer with the right steps. Now, the reason why we're asking this is because it evaluates arithmetic calculations, unit consistency, as well as logical reasoning in multi-step problems. And right away from what i can see is that this model does a great job in logically providing multiple steps and we can see that it utilizes the correct formula which is speed times time and then we can see that it is able to provide the correct answer which is 262.5 miles so therefore this is definitely deemed a pass now next we're gonna have it generate an svg code for a butterfly shape now this is under the category of coding and this is something that many models tend to fail every model that i've tested have has failed this other than the cloud 3.5 sonnet as well as the o1 preview. But let's see if this model is capable of doing this. It's basically testing the understanding of SVG syntax as well as geometric concepts such as symmetry and the ability to generate structured accurate code. So I'm gonna go ahead and copy this and I'm gonna go over to an SVG code simulator to see if this is real. So let's go ahead and copy this and let's go over to an SVG viewer and paste this in. And look at that. Surprisingly, it is accurate. And this does look like a butterfly in my opinion. And this is quite surprising because many models tend to fail at doing this task. So this is a really good sign to see that it is passing at generating SVG code. Now, next up, we're going to have it design an algorithm to optimize a layout for a warehouse. So we can go back into Gemini Studio and then paste in this prompt. Now, essentially, this is a prompt that is under the problem solving and algorithm design category, where we're trying to measure abstract problem-solving as well as algorithmic thinking as well as the ability to balance competing priorities now what we're trying to look for in this prompt is where it's capable of using graph data structures as well as implementing algorithms or dynamic programming right off the bat I can see that it is focusing on applying different algorithms such as ABC analysis. You have cube per order index as well as clustering algorithms like K-means where it is grouping frequently ordered items together. So we can see that it does a great job in listing out the algorithms as well as handling the trade-offs and implementation steps. So this is definitely deemed a pass. So I'm going to go ahead and give this a pass. Next up, we're going to have it create the Python implementation of Conway's Game of Life. Now, every model tends to do a good job in terms of generating the code for this, but it is kind of wonky at certain times with many open source models. The only model that I saw it was capable of generating a full game of this was the Cloud 3.5 Sonnet as well as the O1 Preview. So let's go ahead and see if it's able to create the basic Python script for it. And essentially, this is where we're testing algorithmic implementation, knowledge of cellular autonomy, as well as the ability to structure terminal output. So once I've finished generating this, I'm going to go ahead and paste this into a Python file to see if this is accurate. So I've copied the code and I've pasted it into a VS Code Python file. So let's go ahead and see if it's functional. And there we go. It is definitely functional. It is autonomously generating the game of life so let's go ahead into our benchmark test and give this a pass moving forward we have another prompt which is going to assess logic as well as puzzle so let's go back into the ai studio and paste in this prompt essentially this is where we're assessing how well the model is in terms of evaluating logical reasoning and problem-solving capabilities with constraints because this is where we're asking you have a three gallon jug and a five gallon jug how can you measure four gallons of water efficiently now essentially you have to use a six step process in this case we have that six step process being recognized over here where you fill up the five gallon jug completely you then pour the water from the five gallon into the three gallon until the ladder is full leaving two gallons in the five gallon jug and essentially you'll you're going to be left off with four gallons remaining in the five gallon jug which is definitely correct so this is something that is definitely a pass on the benchmark sheet and that is really really good to see now next up we have this question that is focusing on writing and empathy so let's go ahead into the studio and send in this prompt this is where we're focusing on how well the model is in terms of emotional intelligence, as well as empathy, as well as its written communication skills. So right off the bat, you can see that it's asking a question back to us where it's asking in a human-like manner. Now I'm gonna go ahead and I'm gonna keep on writing to see what it's able to generate and how it's able to communicate with me. So essentially what the prompt is saying is that a friend tells you that he didn't get a job that he really wanted. So I'm requesting it to craft an empathetic response and acknowledge their feelings. So we can see right off the bat, the model responds, oh, I'm so sorry to hear that. And it's totally understandable that you're disappointed, especially since you really wanted that job. That must be rough. And you can see that this is showcasing an empathetic response back to the person. And we can see that it is asking questions on what you're thinking. So I stated that the friend was thinking about feeling hopeless and nothing going his way. And then you can see that it is showing lots of levels of empathy in this response over here and this is definitely something that is showcasing strong emotional intelligence so i'm going to go ahead to the benchmark test and give this a pass so far it has been succeeding really really well now next up we're going to be testing the ethical category of how well this model is in terms of providing a good ethical response. So let's go back into the studio and let's have it generate a response. The prompt is asking, a self-driven car must choose between hitting a group of pedestrians or swerving and likely killing its single passenger. What ethical considerations are involved in programming such decisions? Now, what we're trying to see is if it's able to consider utilitarianism, where there's minimizing overall harm. You also have transparency, legal implications, and public trust. And right off the bat, we can see that it is focusing on a lot of these different things. And it's also emphasizing on a lot of other considerations. So this is something where it's focusing on deontology and rights, where it's focusing on the perspective of emphasizing moral duties, as well as preserving the passenger's right of safety, justice and fairness, public acceptance and trust, and so much more. So there's no single right answer to these ethical questions and that is definitely correct because it is something where you're considering various sorts of views and perspectives to give a basis of this answer so this is definitely deemed a pass on this benchmark test now next up we're going to have it write a short story in approximately 150 words so let's go back into this video and send this in now what we're going to have it write a short story in approximately 150 words. So let's go back into the studio and send this in. Now, what we're trying to see with this is if it's focusing on a good creative theme where it effectively explores a butterfly effect scenario with a significant historical consequence it focuses on a narrative structure where it's clear where there's two different paragraphs focuses on a conflict as well as a resolution within this last paragraph and there's adherence to the prompt where it focuses on closely focusing on time travel and historical change as a theme. Now, this is definitely deemed a pass. So let's go ahead into our benchmark test and give this a pass. Lastly, we're going to have it explain the difference between irony and sarcasm and provide an example for each. Now, this is obviously a really basic prompt, but essentially it tests the model in terms of its language and knowledge. And it focuses on evaluating the understanding of nouns, languages, as well as its concepts and the ability to provide clear examples for each. And right off the bat, we can see for sarcasm, it defines it and it provides a breakdown with each example, focusing on irony irony whether that's situational and where it focuses on a lot of different types of irony from verbal situational and dramatic so this is definitely deemed a pass and this is the first time where i've seen on this channel where a model is able to pass all of these different prompts so huge props to the google Gemini team obviously these are just simple benchmark tests from testing a model in terms of how well it's able to provide generations for various categories but you can see that even with the chatbot arena where it's able to provide great scores on arena vision as well as on the main arena benchmark test we can see that this model even outpaces many of these other models that's out there on a community driven evaluation. Now this is a model that I definitely recommend that you try out. You can access it currently for free off of Google's AI Studio, which I'll leave a link to in the description below. But that's essentially it for this model guys. I definitely love what Google is doing. This is the first time ever where they have outpaced opening as flagship models as well as anthropics flagship models i'll leave all the links that i use in today's video in the description below make sure you follow me on the patreon so that you can access our patreon subscriptions that we give out on a monthly basis for free make sure you follow me on twitter a great way for you to stay up to date with whatever is happening in the world of ai lastly subscribe turn on notification bell like this video and check out our previous videos so that you can stay up to date with whatever is happening in the world of ai but with that thought guys have an amazing day spread positivity and i'll see you guys fairly shortly peace out fellas"}